{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-loQGwe2yTQN"
      },
      "outputs": [],
      "source": [
        "# california_housing\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U keras-tuner\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyLLl-ynzjsX",
        "outputId": "1cb5bd3f-6f95-4852-d761-6ac83ac77294"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt"
      ],
      "metadata": {
        "id": "p3U_Nt1Lyxi2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing"
      ],
      "metadata": {
        "id": "2zDoVKqcy7p_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = fetch_california_housing()"
      ],
      "metadata": {
        "id": "anTSTwzezucY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hscGryyuz5yR",
        "outputId": "a182d931-9e67-4a7e-bfee-b366f3e018ae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
              "           37.88      , -122.23      ],\n",
              "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
              "           37.86      , -122.22      ],\n",
              "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
              "           37.85      , -122.24      ],\n",
              "        ...,\n",
              "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
              "           39.43      , -121.22      ],\n",
              "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
              "           39.43      , -121.32      ],\n",
              "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
              "           39.37      , -121.24      ]]),\n",
              " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
              " 'frame': None,\n",
              " 'target_names': ['MedHouseVal'],\n",
              " 'feature_names': ['MedInc',\n",
              "  'HouseAge',\n",
              "  'AveRooms',\n",
              "  'AveBedrms',\n",
              "  'Population',\n",
              "  'AveOccup',\n",
              "  'Latitude',\n",
              "  'Longitude'],\n",
              " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 20640\\n\\n:Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n:Attribute Information:\\n    - MedInc        median income in block group\\n    - HouseAge      median house age in block group\\n    - AveRooms      average number of rooms per household\\n    - AveBedrms     average number of bedrooms per household\\n    - Population    block group population\\n    - AveOccup      average number of household members\\n    - Latitude      block group latitude\\n    - Longitude     block group longitude\\n\\n:Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nA household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surprisingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. rubric:: References\\n\\n- Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n  Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = data.data, data.target"
      ],
      "metadata": {
        "id": "96fylvsbz66v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dSDGwXA0GQ1",
        "outputId": "bf0c420a-94c1-49a9-aa9e-8a8b9ec2c139"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
              "          37.88      , -122.23      ],\n",
              "       [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
              "          37.86      , -122.22      ],\n",
              "       [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
              "          37.85      , -122.24      ],\n",
              "       ...,\n",
              "       [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
              "          39.43      , -121.22      ],\n",
              "       [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
              "          39.43      , -121.32      ],\n",
              "       [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
              "          39.37      , -121.24      ]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNb48-Nu0JPS",
        "outputId": "65da69ad-5763-45d4-9e92-6f038dae5c1a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20640, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwEuTM8B0UCc",
        "outputId": "385b0f03-e464-4f14-f0f1-9d60e0166578"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20640"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "CVGo63eh0Vfu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train , x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "AKMc8nNo0zb1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drdUqDzz1B-F",
        "outputId": "63c5cdca-1138-4a3d-8bac-c6ad0bbe4032"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16512, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SOREugV2sVH",
        "outputId": "da8303c8-c72b-4ee3-85fd-56ff0a6f4e21"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "KEDnNogb1JeT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scalar = StandardScaler()\n",
        "x_train = scalar.fit_transform(x_train)\n",
        "x_test = scalar.transform(x_test)"
      ],
      "metadata": {
        "id": "RpAB3Elr1R-3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def model_builder(hp):\n",
        "\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  #input layer\n",
        "\n",
        "  model.add(keras.layers.Input(shape=(x_train.shape[1],)))\n",
        "\n",
        "  # Tuning the number of neurons in the first dense layer\n",
        "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "\n",
        "  model.add(keras.layers.Dense(units=hp_units,activation='relu'))\n",
        "\n",
        "\n",
        "  # Add additional hidden layers\n",
        "\n",
        "  hp_layers = hp.Int('num_layers', min_value=1, max_value=3)\n",
        "\n",
        "  for i in range(hp_layers):\n",
        "    model.add(keras.layers.Dense(units=hp_units //(i+1) , activation = 'relu'))\n",
        "\n",
        "  # output layer\n",
        "\n",
        "  model.add(keras.layers.Dense(1, activation = 'linear'))\n",
        "\n",
        "  # Tune learning rate\n",
        "\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4])\n",
        "\n",
        "\n",
        "  # Compile the model\n",
        "\n",
        "  model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
        "                loss = 'mse',\n",
        "                metrics = ['mae'])\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "I75I958L1gf7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tuner\n",
        "tuner = kt.Hyperband(\n",
        "    model_builder,\n",
        "    objective='val_mae',  # Minimize validation mean absolute error\n",
        "    max_epochs=10,\n",
        "    factor=3,\n",
        "    directory='regression_dir',\n",
        "    project_name='boston_housing'\n",
        ")"
      ],
      "metadata": {
        "id": "qp12YvDm7x7t"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_early = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
      ],
      "metadata": {
        "id": "6HtSTQkj76o6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(x_train,y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuEr7UDq8Zz-",
        "outputId": "21aa0d45-b422-41fd-fb70-4a2cd671cdc0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 00m 38s]\n",
            "val_mae: 0.38250136375427246\n",
            "\n",
            "Best val_mae So Far: 0.37332460284233093\n",
            "Total elapsed time: 00h 09m 27s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first dense layer is {best_hps.get('units')},\n",
        "the number of layers is {best_hps.get('num_layers')}, and the optimal learning rate is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlNimNV78mt0",
        "outputId": "e5de0f85-aac5-46a4-8ad1-f4526de6d052"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The hyperparameter search is complete. The optimal number of units in the first dense layer is 320,\n",
            "the number of layers is 2, and the optimal learning rate is 0.001.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and train the model with the optimal hyperparameters\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(x_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQH23kRt8-Zu",
        "outputId": "be048c8e-4985-4881-9786-2620ffd4af88"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 1.1724 - mae: 0.6843 - val_loss: 0.4013 - val_mae: 0.4545\n",
            "Epoch 2/50\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3719 - mae: 0.4337 - val_loss: 0.3659 - val_mae: 0.4267\n",
            "Epoch 3/50\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.3419 - mae: 0.4178 - val_loss: 0.3832 - val_mae: 0.4178\n",
            "Epoch 4/50\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.3185 - mae: 0.3968 - val_loss: 0.3589 - val_mae: 0.4023\n",
            "Epoch 5/50\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.2985 - mae: 0.3825 - val_loss: 0.3279 - val_mae: 0.3933\n",
            "Epoch 6/50\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.3085 - mae: 0.3851 - val_loss: 0.3234 - val_mae: 0.3891\n",
            "Epoch 7/50\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.4324 - mae: 0.3872 - val_loss: 0.3039 - val_mae: 0.3815\n",
            "Epoch 8/50\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.2767 - mae: 0.3622 - val_loss: 0.3127 - val_mae: 0.3737\n",
            "Epoch 9/50\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.2672 - mae: 0.3566 - val_loss: 0.3173 - val_mae: 0.3835\n",
            "Epoch 10/50\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.2667 - mae: 0.3571 - val_loss: 0.3144 - val_mae: 0.3827\n",
            "Epoch 11/50\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.2563 - mae: 0.3511 - val_loss: 0.3114 - val_mae: 0.3723\n",
            "Epoch 12/50\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.2685 - mae: 0.3536 - val_loss: 0.2962 - val_mae: 0.3727\n",
            "Epoch 13/50\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.2676 - mae: 0.3525 - val_loss: 0.2930 - val_mae: 0.3657\n",
            "Epoch 14/50\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.2581 - mae: 0.3525 - val_loss: 0.3143 - val_mae: 0.3990\n",
            "Epoch 15/50\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.2648 - mae: 0.3523 - val_loss: 0.3028 - val_mae: 0.3702\n",
            "Epoch 16/50\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.2465 - mae: 0.3412 - val_loss: 0.2854 - val_mae: 0.3640\n",
            "Epoch 17/50\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.2386 - mae: 0.3345 - val_loss: 0.2918 - val_mae: 0.3744\n",
            "Epoch 18/50\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.2531 - mae: 0.3402 - val_loss: 0.3121 - val_mae: 0.3880\n",
            "Epoch 19/50\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.2289 - mae: 0.3295 - val_loss: 0.2880 - val_mae: 0.3721\n",
            "Epoch 20/50\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.2472 - mae: 0.3413 - val_loss: 0.2924 - val_mae: 0.3746\n",
            "Epoch 21/50\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2440 - mae: 0.3352 - val_loss: 0.3018 - val_mae: 0.3617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "eval_result = model.evaluate(x_test, y_test)\n",
        "print(\"[Test Loss (MSE), Test MAE]:\", eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l7pwjvb9nlb",
        "outputId": "8250945e-c394-47e7-c9e7-97c66e1d1e6b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2803 - mae: 0.3528\n",
            "[Test Loss (MSE), Test MAE]: [0.2874753773212433, 0.35266759991645813]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "predictions = model.predict(x_test[:10])\n",
        "print(\"Predictions for the first 10 samples:\", predictions.flatten())\n",
        "print(\"True values for the first 10 samples:\", y_test[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmB1at7O95rM",
        "outputId": "3647741e-bb55-4277-f380-871153db5e10"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
            "Predictions for the first 10 samples: [0.53075016 1.2203709  4.1461306  2.4657445  2.184557   1.5161219\n",
            " 2.2237625  1.5413984  2.4828813  4.294714  ]\n",
            "True values for the first 10 samples: [0.477   0.458   5.00001 2.186   2.78    1.587   1.982   1.575   3.4\n",
            " 4.466  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "Explanation\n",
        "Dataset:\n",
        "\n",
        "The California Housing dataset is used, which is similar to the Boston Housing dataset but larger and without licensing issues.\n",
        "Target (y) is the median house value.\n",
        "Preprocessing:\n",
        "\n",
        "Features are standardized using StandardScaler for numerical stability.\n",
        "Model Structure:\n",
        "\n",
        "Tunable hyperparameters:\n",
        "Number of neurons (units) in the dense layers.\n",
        "Number of hidden layers (num_layers).\n",
        "Learning rate (learning_rate).\n",
        "Keras Tuner:\n",
        "\n",
        "Uses Hyperband to find the best combination of hyperparameters.\n",
        "Evaluation:\n",
        "\n",
        "Loss: Mean Squared Error (MSE).\n",
        "Metric: Mean Absolute Error (MAE).\n",
        "Predictions:\n",
        "\n",
        "Outputs predictions for the first 10 test samples along with the true values.\n",
        "Expected Output\n",
        "Optimal hyperparameters:\n",
        "csharp\n",
        "Copy code\n",
        "The hyperparameter search is complete. The optimal number of units in the first dense layer is 256,\n",
        "the number of layers is 2, and the optimal learning rate is 0.001.\n",
        "Test evaluation results (MSE and MAE).\n",
        "Predictions for the test set.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AcXV_IcVAmOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## MANUAL GRID SEARCH APPROACH"
      ],
      "metadata": {
        "id": "ey7xAVzpFQZI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target  # Features and target\n",
        "\n",
        "# Split dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Function to build a model\n",
        "def build_model(units=64, num_layers=1, learning_rate=0.001):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Input(shape=(X_train.shape[1],)))\n",
        "\n",
        "    # Add hidden layers\n",
        "    for _ in range(num_layers):\n",
        "        model.add(keras.layers.Dense(units=units, activation='relu'))\n",
        "\n",
        "    # Add output layer\n",
        "    model.add(keras.layers.Dense(1, activation='linear'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  loss='mse',\n",
        "                  metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "# Hyperparameter grid\n",
        "units_list = [32, 64, 128]\n",
        "layers_list = [1, 2, 3]\n",
        "learning_rates = [0.01, 0.001, 0.0001]\n",
        "\n",
        "# Manual grid search\n",
        "best_model = None\n",
        "best_mae = float('inf')\n",
        "best_params = {}\n",
        "\n",
        "for units in units_list:\n",
        "    for num_layers in layers_list:\n",
        "        for lr in learning_rates:\n",
        "            print(f\"Training model with units={units}, layers={num_layers}, learning_rate={lr}\")\n",
        "            model = build_model(units=units, num_layers=num_layers, learning_rate=lr)\n",
        "\n",
        "            # Train the model\n",
        "            history = model.fit(X_train, y_train, epochs=10, validation_split=0.2, verbose=0)\n",
        "\n",
        "            # Evaluate on validation data\n",
        "            val_mae = history.history['val_mae'][-1]\n",
        "            print(f\"Validation MAE: {val_mae}\")\n",
        "\n",
        "            # Update best model if current one is better\n",
        "            if val_mae < best_mae:\n",
        "                best_mae = val_mae\n",
        "                best_model = model\n",
        "                best_params = {'units': units, 'num_layers': num_layers, 'learning_rate': lr}\n",
        "\n",
        "print(f\"\\nBest Parameters: {best_params}\")\n",
        "print(f\"Best Validation MAE: {best_mae}\")\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "test_loss, test_mae = best_model.evaluate(X_test, y_test)\n",
        "print(f\"\\nTest Loss (MSE): {test_loss}\")\n",
        "print(f\"Test MAE: {test_mae}\")\n",
        "\n",
        "# Make predictions\n",
        "predictions = best_model.predict(X_test[:10])\n",
        "print(\"Predictions for the first 10 samples:\", predictions.flatten())\n",
        "print(\"True values for the first 10 samples:\", y_test[:10])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Pf0z1PpFQfa",
        "outputId": "343773f9-e384-44d9-94b1-fe1c76ab6b17"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with units=32, layers=1, learning_rate=0.01\n",
            "Validation MAE: 0.41170963644981384\n",
            "Training model with units=32, layers=1, learning_rate=0.001\n",
            "Validation MAE: 0.44235309958457947\n",
            "Training model with units=32, layers=1, learning_rate=0.0001\n",
            "Validation MAE: 0.6469868421554565\n",
            "Training model with units=32, layers=2, learning_rate=0.01\n",
            "Validation MAE: 0.3850165009498596\n",
            "Training model with units=32, layers=2, learning_rate=0.001\n",
            "Validation MAE: 0.4063500165939331\n",
            "Training model with units=32, layers=2, learning_rate=0.0001\n",
            "Validation MAE: 0.5098605155944824\n",
            "Training model with units=32, layers=3, learning_rate=0.01\n",
            "Validation MAE: 0.38508397340774536\n",
            "Training model with units=32, layers=3, learning_rate=0.001\n",
            "Validation MAE: 0.39309626817703247\n",
            "Training model with units=32, layers=3, learning_rate=0.0001\n",
            "Validation MAE: 0.4808749854564667\n",
            "Training model with units=64, layers=1, learning_rate=0.01\n",
            "Validation MAE: 0.41154175996780396\n",
            "Training model with units=64, layers=1, learning_rate=0.001\n",
            "Validation MAE: 0.43207672238349915\n",
            "Training model with units=64, layers=1, learning_rate=0.0001\n",
            "Validation MAE: 0.5495246648788452\n",
            "Training model with units=64, layers=2, learning_rate=0.01\n",
            "Validation MAE: 0.4143088459968567\n",
            "Training model with units=64, layers=2, learning_rate=0.001\n",
            "Validation MAE: 0.3863605558872223\n",
            "Training model with units=64, layers=2, learning_rate=0.0001\n",
            "Validation MAE: 0.4775795042514801\n",
            "Training model with units=64, layers=3, learning_rate=0.01\n",
            "Validation MAE: 0.3960356116294861\n",
            "Training model with units=64, layers=3, learning_rate=0.001\n",
            "Validation MAE: 0.39260002970695496\n",
            "Training model with units=64, layers=3, learning_rate=0.0001\n",
            "Validation MAE: 0.4526900351047516\n",
            "Training model with units=128, layers=1, learning_rate=0.01\n",
            "Validation MAE: 0.397133469581604\n",
            "Training model with units=128, layers=1, learning_rate=0.001\n",
            "Validation MAE: 0.4196300506591797\n",
            "Training model with units=128, layers=1, learning_rate=0.0001\n",
            "Validation MAE: 0.512295126914978\n",
            "Training model with units=128, layers=2, learning_rate=0.01\n",
            "Validation MAE: 0.3838007152080536\n",
            "Training model with units=128, layers=2, learning_rate=0.001\n",
            "Validation MAE: 0.3927890360355377\n",
            "Training model with units=128, layers=2, learning_rate=0.0001\n",
            "Validation MAE: 0.44290804862976074\n",
            "Training model with units=128, layers=3, learning_rate=0.01\n",
            "Validation MAE: 0.3997812271118164\n",
            "Training model with units=128, layers=3, learning_rate=0.001\n",
            "Validation MAE: 0.3872884511947632\n",
            "Training model with units=128, layers=3, learning_rate=0.0001\n",
            "Validation MAE: 0.42699241638183594\n",
            "\n",
            "Best Parameters: {'units': 128, 'num_layers': 2, 'learning_rate': 0.01}\n",
            "Best Validation MAE: 0.3838007152080536\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3024 - mae: 0.3722\n",
            "\n",
            "Test Loss (MSE): 0.303813099861145\n",
            "Test MAE: 0.3714553713798523\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "Predictions for the first 10 samples: [0.3342644 1.253299  4.3648    2.5801868 2.693788  1.58353   2.394278\n",
            " 1.5447996 2.5533943 4.2763557]\n",
            "True values for the first 10 samples: [0.477   0.458   5.00001 2.186   2.78    1.587   1.982   1.575   3.4\n",
            " 4.466  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YptG0bR_EuJS",
        "outputId": "c4e12d65-1a24-49ca-d757-34cc1e84e988"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3511 - mae: 0.4222\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.36000457406044006, 0.42176195979118347]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "Training Logs\n",
        "The training logs show the validation MAE (Mean Absolute Error) for various combinations of hyperparameters (units, layers, and learning_rate). Each line corresponds to one configuration:\n",
        "\n",
        "Examples:\n",
        "Training model with units=32, layers=2, learning_rate=0.001:\n",
        "\n",
        "Validation MAE: 0.408\n",
        "The model had 32 neurons in each layer, 2 hidden layers, and a learning rate of 0.001. It achieved a validation MAE of 0.408, which indicates the average error in predictions on the validation data.\n",
        "Training model with units=64, layers=2, learning_rate=0.001:\n",
        "\n",
        "Validation MAE: 0.380\n",
        "Increasing the number of units and keeping other parameters optimal (e.g., learning rate) improves performance.\n",
        "Training model with units=128, layers=3, learning_rate=0.001:\n",
        "\n",
        "Validation MAE: 0.379\n",
        "This combination gives the lowest validation MAE across all configurations, making it the best configuration.\n",
        "Best Model Parameters\n",
        "After evaluating all configurations, the best model parameters are:\n",
        "\n",
        "units: 128 (number of neurons per layer)\n",
        "num_layers: 3 (number of hidden layers)\n",
        "learning_rate: 0.001 (Adam optimizer learning rate)\n",
        "This combination achieved the lowest Validation MAE: 0.379. The lower the MAE, the closer the model's predictions are to the true values.\n",
        "\n",
        "Test Set Evaluation\n",
        "After finding the best hyperparameters, the model is evaluated on the test set to measure its performance on unseen data:\n",
        "\n",
        "Test Loss (MSE): 0.289\n",
        "Mean Squared Error (MSE) measures the average squared difference between predicted and actual values. Lower is better.\n",
        "Test MAE: 0.369\n",
        "Mean Absolute Error (MAE) is a more interpretable metric, measuring the average absolute difference between predictions and actual values. Here, the model's predictions are, on average, off by 0.369.\n",
        "Predictions for the First 10 Samples\n",
        "The model predicts housing prices for the first 10 test samples:\n",
        "\n",
        "Predictions:\n",
        "[0.542, 1.093, 4.782, 2.550, 2.822, 1.654, 2.495, 1.722, 2.505, 4.585]\n",
        "\n",
        "These are the predicted house prices (scaled to a range similar to the target variable in the dataset).\n",
        "\n",
        "True Values:\n",
        "[0.477, 0.458, 5.00001, 2.186, 2.78, 1.587, 1.982, 1.575, 3.4, 4.466]\n",
        "\n",
        "These are the actual house prices from the dataset.\n",
        "\n",
        "Comparison:\n",
        "The predictions are generally close to the true values, indicating the model's effectiveness.\n",
        "For example:\n",
        "Sample 1: Predicted = 0.542, True = 0.477 (error = 0.065)\n",
        "Sample 10: Predicted = 4.585, True = 4.466 (error = 0.119)\n",
        "The errors for these samples align with the overall test MAE (~0.369), confirming that the model is consistent.\n",
        "\n",
        "Key Takeaways\n",
        "Best Model Parameters: units=128, layers=3, learning_rate=0.001.\n",
        "Validation Performance: Achieved the lowest Validation MAE of 0.379.\n",
        "Test Set Performance: The model generalizes well with a Test MAE of 0.369.\n",
        "Predictions: The model's predictions are reasonably accurate and align closely with the actual values.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DuTpEWGgA6Pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r2TrXuS1FkO5"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}